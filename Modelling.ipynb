{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('Data/clean_data.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['sentiment'], random_state=42)\n",
    "\n",
    "# Display the class distribution in the training set before downsampling\n",
    "print(\"Training set class distribution before downsampling:\")\n",
    "print(train_df['sentiment'].value_counts())\n",
    "\n",
    "# Display the class distribution in the test set\n",
    "print(\"Test set class distribution:\")\n",
    "print(test_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the size of the largest class in the training set\n",
    "max_class_size = train_df['sentiment'].value_counts().max()\n",
    "\n",
    "# Upsample each sentiment class in the training set\n",
    "train_positive = train_df[train_df['sentiment'] == 'positive'].sample(max_class_size, replace=True, random_state=42)\n",
    "train_negative = train_df[train_df['sentiment'] == 'negative'].sample(max_class_size, replace=True, random_state=42)\n",
    "train_neutral = train_df[train_df['sentiment'] == 'neutral'].sample(max_class_size, replace=True, random_state=42)\n",
    "\n",
    "# Combine the upsampled dataframes\n",
    "train_df_upsampled = pd.concat([train_positive, train_negative, train_neutral])\n",
    "\n",
    "# Shuffle the combined dataframe to mix the classes\n",
    "train_df_upsampled = train_df_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the class distribution after downsampling in the training set\n",
    "print(\"Training set class distribution after downsampling:\")\n",
    "print(train_df_upsampled['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fill NaN values in 'nouns_comm' and 'raw_comm' columns with an empty string\n",
    "train_df_upsampled['nouns_comm'] = train_df_upsampled['nouns_comm'].fillna('')\n",
    "train_df_upsampled['raw_comm'] = train_df_upsampled['raw_comm'].fillna('')\n",
    "test_df['nouns_comm'] = test_df['nouns_comm'].fillna('')\n",
    "test_df['raw_comm'] = test_df['raw_comm'].fillna('')\n",
    "\n",
    "# TF-IDF Vectorization for 'nouns_comm' and 'raw_comm'\n",
    "tfidf_vectorizer_nouns = TfidfVectorizer()\n",
    "tfidf_vectorizer_raw = TfidfVectorizer()\n",
    "\n",
    "X_train_nouns = tfidf_vectorizer_nouns.fit_transform(train_df_upsampled['nouns_comm'])\n",
    "X_test_nouns = tfidf_vectorizer_nouns.transform(test_df['nouns_comm'])\n",
    "\n",
    "X_train_raw = tfidf_vectorizer_raw.fit_transform(train_df_upsampled['raw_comm'])\n",
    "X_test_raw = tfidf_vectorizer_raw.transform(test_df['raw_comm'])\n",
    "\n",
    "y_train = train_df_upsampled['sentiment']\n",
    "y_test = test_df['sentiment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train Naive Bayes models for both 'nouns_comm' and 'raw_comm'\n",
    "nb_nouns = MultinomialNB()\n",
    "nb_raw = MultinomialNB()   \n",
    "\n",
    "# Fit the models\n",
    "nb_nouns.fit(X_train_nouns, y_train)\n",
    "nb_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred_nouns = nb_nouns.predict(X_train_nouns)\n",
    "y_train_pred_raw = nb_raw.predict(X_train_raw)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred_nouns = nb_nouns.predict(X_test_nouns)\n",
    "y_test_pred_raw = nb_raw.predict(X_test_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute models' accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Naive Bayes model on the test set ('nouns_comm')\n",
    "print(\"\\nTest Set - Naive Bayes Model on 'nouns_comm'\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_nouns))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred_nouns))\n",
    "\n",
    "# Evaluate the Naive Bayes model on the test set ('raw_comm')\n",
    "print(\"\\nTest Set - Naive Bayes Model on 'raw_comm'\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_raw))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred_raw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add predictions in the test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['NB_pred_noun'] = y_test_pred_nouns\n",
    "test_df['NB_pred_raw'] = y_test_pred_raw\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN with nouns comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the FNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def create_fnn_model(input_dim, layers=1, nodes=32, learning_rate=0.001, dropout_rate=0.5, l2_reg=0.01):\n",
    "    \"\"\"\n",
    "    Creates a feedforward neural network model with L2 regularization and dropout.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Number of input features.\n",
    "        layers (int): Number of hidden layers.\n",
    "        nodes (int): Number of nodes per layer.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        dropout_rate (float): Dropout rate to prevent overfitting.\n",
    "        l2_reg (float): L2 regularization strength.\n",
    "\n",
    "    Returns:\n",
    "        model: Compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, input_dim=input_dim, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    \n",
    "    # Add hidden layers with dropout and L2 regularization\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(nodes, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer with 3 nodes for the 3 classes\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform in Keras wrap and set hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import activations  \n",
    "\n",
    "\n",
    "# Function to create the KerasClassifier model for grid search\n",
    "def build_keras_classifier(input_dim, layers, nodes, learning_rate, dropout_rate=0.5, l2_reg=0.01):\n",
    "    return KerasClassifier(model=create_fnn_model, input_dim=input_dim, layers=layers, \n",
    "                           nodes=nodes, learning_rate=learning_rate, dropout_rate=dropout_rate, \n",
    "                           l2_reg=l2_reg, verbose=0)\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'layers': [3, 5, 7],\n",
    "    'nodes': [128, 256, 512],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'epochs': [20],\n",
    "    'batch_size': [32]\n",
    "}\n",
    "\n",
    "# Build the model\n",
    "input_dim = X_train_nouns.shape[1]\n",
    "model = build_keras_classifier(input_dim=input_dim, layers=1, nodes=32, learning_rate=0.001)\n",
    "\n",
    "# EarlyStopping and ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0.001, \n",
    "    patience=10,  # Stop if no improvement after 10 epochs\n",
    "    verbose=0, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    patience=5,  # Reduce LR if no improvement after 5 epochs\n",
    "    verbose=0, \n",
    "    min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid Search with EarlyStopping and ReduceLROnPlateau callbacks\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_nouns, y_train, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "best_model_nouns = grid_result.best_estimator_\n",
    "\n",
    "# Access the underlying Keras model\n",
    "keras_model_nouns = best_model_nouns.model_\n",
    "\n",
    "# Save the model in the recommended format\n",
    "keras_model_nouns.save('FNN_nouns.keras')\n",
    "\n",
    "# Load the model from the saved file\n",
    "best_model_nouns = load_model('FNN_nouns.keras')\n",
    "\n",
    "# Convert Sentiment labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Evaluate the loaded model with the encoded labels\n",
    "best_model_nouns.evaluate(X_test_nouns, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the mean cross validation accuracy per combination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results from the grid search\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Extract the mean and standard deviation of test scores, and the corresponding parameters\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "# Print the results in a readable format\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain the best model to store the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Retrieve the best hyperparameters from GridSearchCV\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Create the final model using the best parameters\n",
    "best_model = create_fnn_model(\n",
    "    input_dim=X_train_nouns.shape[1],\n",
    "    layers=best_params['layers'],\n",
    "    nodes=best_params['nodes'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    ")\n",
    "\n",
    "# Model Summary\n",
    "print(best_model.summary())\n",
    "\n",
    "# EarlyStopping to stop training when validation loss has not improved\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0.001, \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau to reduce the learning rate when validation loss has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    min_lr=0.0005\n",
    ")\n",
    "\n",
    "# ModelCheckpoint to save the model after every epoch\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras', \n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fit the model using the encoded labels\n",
    "history = best_model.fit(\n",
    "    X_train_nouns, y_train_encoded,  # <-- Use encoded labels here\n",
    "    epochs=best_params['epochs'],  # Use the best number of epochs from the grid search\n",
    "    batch_size=best_params['batch_size'],  # Use the best batch size from the grid search\n",
    "    validation_split=0.2,  # Using 20% of the training data as validation data\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the history of the loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss and accuracy.\n",
    "\n",
    "    Args:\n",
    "        history: Keras History object returned by model.fit().\n",
    "    \"\"\"\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training and validation loss/accuracy using the history object\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test set with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model from GridSearchCV\n",
    "best_model_nouns = grid_result.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model_nouns.predict(X_test_nouns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute metrics of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = best_model_nouns.score(X_test_nouns, y_test)\n",
    "print(\"Test set accuracy: {:.4f}\".format(test_accuracy))\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN with raw comms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with raw comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid Search with EarlyStopping and ReduceLROnPlateau on raw comments\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_raw, y_train, callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the model\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "best_model_raw = grid_result.best_estimator_\n",
    "\n",
    "# Access the underlying Keras model\n",
    "keras_model_raw = best_model_raw.model_\n",
    "\n",
    "# Save the model in the recommended format\n",
    "keras_model_raw.save('FNN_raw.keras')\n",
    "\n",
    "# Load the model from the saved file\n",
    "best_model_raw = load_model('FNN_raw.keras')\n",
    "\n",
    "# Convert Sentiment labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Evaluate the loaded model with the encoded labels\n",
    "best_model_nouns.evaluate(X_test_nouns, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model from GridSearchCV\n",
    "best_model_raw = grid_result.best_estimator_\n",
    "\n",
    "# Access the underlying Keras model\n",
    "keras_model_raw = best_model_raw.model_\n",
    "\n",
    "# Save the best model trained on raw comments\n",
    "keras_model_raw.save('fnn_raw_model.keras')\n",
    "\n",
    "# Retrain the best model on the full training set and store the training history\n",
    "history = best_model_raw.model_.fit(\n",
    "    X_train_raw, y_train, \n",
    "    epochs=best_model_raw.get_params()['epochs'], \n",
    "    batch_size=best_model_raw.get_params()['batch_size'],\n",
    "    validation_split=0.2,  # Use 20% of the training data for validation\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the training and validation accuracy and loss using the history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics with raw comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Retrieve the best model from GridSearchCV\n",
    "best_model_raw = grid_result.best_estimator_\n",
    "\n",
    "# Make predictions on the test set (use X_test_raw instead of X_test_nouns)\n",
    "y_test_pred = best_model_raw.predict(X_test_raw)\n",
    "\n",
    "# Evaluate the model on the test set (using raw comments)\n",
    "test_accuracy = best_model_raw.score(X_test_raw, y_test)\n",
    "print(\"Test set accuracy: {:.4f}\".format(test_accuracy))\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with nouns comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
